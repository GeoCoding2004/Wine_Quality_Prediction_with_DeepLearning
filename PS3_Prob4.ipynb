{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37CazUeqrjCq"
      },
      "outputs": [],
      "source": [
        "#importing libraries\n",
        "import torch\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming that the data is in a CSV file\n",
        "def Data_set(filename, input_features, output_features):\n",
        "\n",
        "    input_data = pd.read_csv(filename, usecols= input_features).astype(np.float32)\n",
        "\n",
        "    output_data = pd.read_csv(filename, usecols=output_features).astype(np.float32)\n",
        "\n",
        "    # Convert data to tensors\n",
        "    input_tensor = torch.tensor(input_data.values)\n",
        "    output_tensor = torch.tensor(output_data.values)\n",
        "\n",
        "    return input_tensor, output_tensor\n"
      ],
      "metadata": {
        "id": "YozQvlcJr3vR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Data_set_split(input_tensor, output_tensor, test_size=0.2):\n",
        "    #Convert to numpy for compatibility with train_test_split\n",
        "    input_numpy = input_tensor.numpy()\n",
        "    output_numpy = output_tensor.numpy()\n",
        "\n",
        "    # Split the data (80% training, 20% testing)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(input_numpy, output_numpy, test_size=test_size, random_state=42)\n",
        "\n",
        "    # Convert back to tensors\n",
        "    input_train = torch.tensor(X_train, requires_grad=True)\n",
        "    output_train = torch.tensor(y_train, requires_grad=True)\n",
        "    input_test = torch.tensor(X_test, requires_grad=True)\n",
        "    output_test = torch.tensor(y_test, requires_grad=True)\n",
        "\n",
        "    return input_train,output_train,input_test,output_test\n",
        "\n"
      ],
      "metadata": {
        "id": "qINqhRdZr7pY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, architecture, activation_function):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.activation_function = activation_function  # Store the activation function as an attribute\n",
        "\n",
        "        for i in range(len(architecture)-1):\n",
        "            self.layers.append(nn.Linear(architecture[i], architecture[i+1]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            x = layer(x)\n",
        "            # Apply activation to all but last layer\n",
        "            if i < len(self.layers) - 1:\n",
        "                x = self.activation_function(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "1uNHTrIbr-nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Create_model(architecture,activation_function):\n",
        "    # Instantiate the network\n",
        "    return NeuralNet(architecture,activation_function)"
      ],
      "metadata": {
        "id": "P6Ndecw5sC4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Train_model(train_input, train_output, optimizer_type, model, epochs, learning_rate):\n",
        "\n",
        "    # Define mean squared error loss\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    # Define optimizer\n",
        "    optimizer = optimizer_type(model.parameters(), learning_rate)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):  # epochs\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        predicted_output = model(input_training)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(predicted_output, output_training)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch == epochs:\n",
        "            print(f\"Epoch {epoch}/{epochs}, Training Loss: {loss.item()}\")"
      ],
      "metadata": {
        "id": "Mijl5si_sDwP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Test_loss(model,input_testing,output_testing, criterion):\n",
        "    test_predicted = model(input_testing)\n",
        "    test_loss = criterion(test_predicted, output_testing)\n",
        "    return test_loss.item()"
      ],
      "metadata": {
        "id": "TjPVZpevsD-A"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Prediction(model, input_testing):\n",
        "    with torch.no_grad():\n",
        "        # We don't need gradients for prediction\n",
        "        predicted = model(input_testing)\n",
        "        # Convert tensor to float\n",
        "        return predicted.item() if predicted.numel() == 1 else predicted.numpy()"
      ],
      "metadata": {
        "id": "6xSOeuRSsJlg"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting the inputs/outputs and splitting the data\n",
        "\n",
        "input_features = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar','chlorides',\n",
        "                  'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH','sulphates', 'alcohol']\n",
        "\n",
        "output_features = ['quality']\n",
        "\n",
        "torch.manual_seed(42)  # Set seed (used so that we don't have each time we run the code a different test error)\n",
        "\n",
        "input_tensor,output_tensor = Data_set('WineQT.csv', input_features, output_features)\n",
        "input_training, output_training, input_testing, output_testing = Data_set_split(input_tensor, output_tensor)"
      ],
      "metadata": {
        "id": "0G4mjrf3sQLw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Case 1:\n",
        "No hidden layers (11 inputs are directly connected to the output). The output loss and error are NaN, which indicates that they have diverged to very large values. This issue likely arises from the network's inability to learn effectively due to the absence of hidden layers, resulting in the accumulation of errors."
      ],
      "metadata": {
        "id": "qHnVuU0ou0L_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Case 1\n",
        "architecture = [11,1]\n",
        "\n",
        "model = Create_model(architecture,nn.ReLU())\n",
        "Train_model(input_training, output_training, optim.SGD, model, 1000, 0.001)\n",
        "\n",
        "testLoss = Test_loss(model,input_testing,output_testing,nn.MSELoss())\n",
        "print(\"Test loss:\", testLoss)\n",
        "\n",
        "\n",
        "x = torch.tensor([8.3, 0.655,0.12,2.3,0.083,15,113,0.9966,3.17,0.66,9.8])\n",
        "pred = Prediction(model, x)\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBIA_Gr_tvPR",
        "outputId": "647ce7b3-ceb1-4f29-a2e7-7f0d0ce74254"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: nan\n",
            "nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Case 2:\n",
        "The additional hidden layer with 8 nodes helps the model capture more complex relationships in the data, reducing the error from very large (like in case 1, the output is NaN), to a reasonable test error of 0.40830376744270325. <br>\n",
        "The example provided has an expected output of 5, but the prediction found was 4.885446071624756"
      ],
      "metadata": {
        "id": "DxZvqu1nwigW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Case 2\n",
        "torch.manual_seed(42)  # Set seed (used so that we don't have each time we run the code a different test error)\n",
        "architecture = [11,8,1]\n",
        "\n",
        "model = Create_model(architecture,nn.ReLU())\n",
        "Train_model(input_training, output_training, optim.SGD, model, 1000, 0.001)\n",
        "\n",
        "testLoss = Test_loss(model,input_testing,output_testing,nn.MSELoss())\n",
        "print(\"Test loss:\", testLoss)\n",
        "\n",
        "\n",
        "x = torch.tensor([8.3, 0.655,0.12,2.3,0.083,15,113,0.9966,3.17,0.66,9.8])\n",
        "pred = Prediction(model, x)\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oi42lm2Fv_7J",
        "outputId": "1e9885b9-be0f-4774-95f7-4d24c6a9c3ee"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.4199908971786499\n",
            "5.317503929138184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Case 3:\n",
        "Adding an additional hidden layer with 5 nodes helps the model capture more complex relationships in the data. <br>\n",
        "But we can see that the test loss increased. This is due to the increased complexity of the neural network with not enough epochs to reduce this error. <br>\n",
        "This is why increasing the complexity but keeping the same number of epochs increased the test loss to 0.45804181694984436"
      ],
      "metadata": {
        "id": "BVlWPLh5zNst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Case 3\n",
        "\n",
        "architecture = [11,8,5,1]\n",
        "\n",
        "model = Create_model(architecture,nn.ReLU())\n",
        "Train_model(input_training, output_training, optim.SGD, model, 1000, 0.001)\n",
        "\n",
        "testLoss = Test_loss(model,input_testing,output_testing,nn.MSELoss())\n",
        "print(\"Test loss:\", testLoss)\n",
        "\n",
        "\n",
        "x = torch.tensor([8.3, 0.655,0.12,2.3,0.083,15,113,0.9966,3.17,0.66,9.8])\n",
        "pred = Prediction(model, x)\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOMBsf8xxqnn",
        "outputId": "4692eb82-ebf4-46be-f813-286b880006b4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.45804181694984436\n",
            "5.518387794494629\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Case 4\n",
        "In this case, we increased the number of epochs from 1000 to 5000 to account for the additional complexity of the neural network. <br>\n",
        "The test loss is reduced to 0.38506579399108887"
      ],
      "metadata": {
        "id": "rievte4_0JXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Case 4\n",
        "\n",
        "architecture = [11,8,5,1]\n",
        "\n",
        "model = Create_model(architecture,nn.ReLU())\n",
        "Train_model(input_training, output_training, optim.SGD, model, 5000, 0.001)\n",
        "\n",
        "testLoss = Test_loss(model,input_testing,output_testing,nn.MSELoss())\n",
        "print(\"Test loss:\", testLoss)\n",
        "\n",
        "\n",
        "x = torch.tensor([8.3, 0.655,0.12,2.3,0.083,15,113,0.9966,3.17,0.66,9.8])\n",
        "pred = Prediction(model, x)\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfS2HcnPzIVu",
        "outputId": "93e3b5e6-b6f9-4141-bc5e-d1719b908b1d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.38506579399108887\n",
            "5.1290411949157715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Case 5\n",
        "In this case, we changed the activation function to Tanh. <br>\n",
        "The loss increased to 0.5583304762840271. <br>\n",
        "This is mainly due to the fact that ReLU converges faster, arriving at a lower test loss faster than Tanh"
      ],
      "metadata": {
        "id": "9hWA8HxB0wAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Case 5\n",
        "\n",
        "architecture = [11,8,5,1]\n",
        "\n",
        "model = Create_model(architecture,nn.Tanh())\n",
        "Train_model(input_training, output_training, optim.SGD, model, 5000, 0.001)\n",
        "\n",
        "testLoss = Test_loss(model,input_testing,output_testing,nn.MSELoss())\n",
        "print(\"Test loss:\", testLoss)\n",
        "\n",
        "\n",
        "x = torch.tensor([8.3, 0.655,0.12,2.3,0.083,15,113,0.9966,3.17,0.66,9.8])\n",
        "pred = Prediction(model, x)\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWukOc4Z0Yk2",
        "outputId": "7a61cf7b-d0b6-43df-a56f-10edfa05e228"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.5583304762840271\n",
            "5.6222076416015625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Case 6\n",
        "Using Adam optimizer instead of Stochastic Gradient Descent to train the model reduced the test loss to 0.3514178395271301. <br>\n"
      ],
      "metadata": {
        "id": "afvoXkZo1wAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Case 6\n",
        "\n",
        "architecture = [11,8,5,1]\n",
        "\n",
        "model = Create_model(architecture,nn.Tanh())\n",
        "Train_model(input_training, output_training, optim.Adam, model, 5000, 0.001)\n",
        "\n",
        "testLoss = Test_loss(model,input_testing,output_testing,nn.MSELoss())\n",
        "print(\"Test loss:\", testLoss)\n",
        "\n",
        "\n",
        "x = torch.tensor([8.3, 0.655,0.12,2.3,0.083,15,113,0.9966,3.17,0.66,9.8])\n",
        "pred = Prediction(model, x)\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAGFyCjQ1a7f",
        "outputId": "4445d0dc-2e19-4a0f-e4ed-4301b72ce14c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.3514178395271301\n",
            "5.195265293121338\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Case 7\n",
        "Using ASGD (Averaged Stochastic Gradient Descent) as optimizer instead of Adam and SGD increases the test loss to 0.5557608604431152"
      ],
      "metadata": {
        "id": "iygCrCQO2f38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Case 7\n",
        "\n",
        "architecture = [11,8,5,1]\n",
        "\n",
        "model = Create_model(architecture,nn.Tanh())\n",
        "Train_model(input_training, output_training, optim.ASGD , model, 5000, 0.001)\n",
        "\n",
        "testLoss = Test_loss(model,input_testing,output_testing,nn.MSELoss())\n",
        "print(\"Test loss:\", testLoss)\n",
        "\n",
        "\n",
        "x = torch.tensor([8.3, 0.655,0.12,2.3,0.083,15,113,0.9966,3.17,0.66,9.8])\n",
        "pred = Prediction(model, x)\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTCYHECS2LfN",
        "outputId": "b4f9137f-23cc-476d-8b14-2de6266d51c4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.5557608604431152\n",
            "5.660046577453613\n"
          ]
        }
      ]
    }
  ]
}